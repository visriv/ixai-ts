{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d7000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# BASE_DIR = Path(\"../runs/var_local\")\n",
    "# BASE_DIR = Path(\"../runs/lorenz\")\n",
    "BASE_DIR = Path(\"../runs/cltts\")\n",
    "TAU_MAX = 25  # adjust if needed\n",
    "interaction_method = \"ih\" \n",
    "FEATURE_IDX_0 = 0\n",
    "FEATURE_IDX_1 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53f7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Discovered hyperparams in run dirs:\n",
      "  a1: [0.05, 0.1, 0.2, 0.4]\n",
      "  d_model: [16]\n",
      "  interaction_method: ['ih']\n",
      "  layers: [2]\n",
      "  model: ['transformer']\n",
      "  noise: [0.05]\n",
      "  num_permutations: [20]\n",
      "  tau_max: [25]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "group_by_d_model() got an unexpected keyword argument 'interaction_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 329\u001b[0m\n\u001b[1;32m    270\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# plot_grouped_curves(group_by_a1(\"transformer\", noise=0.05),\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#                     tau_max=TAU_MAX, use=\"mean\", title=\"Transformer: Effect of a1; noise = 0.05\", log_y=logy)\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# same axes; vary d_model (keep layers fixed)\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m plot_grouped_curves(\u001b[43mgroup_by_d_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43ma1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43minteraction_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minteraction_method\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    334\u001b[0m                     tau_max\u001b[38;5;241m=\u001b[39mTAU_MAX, use\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m                     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer: effect of d_model; noise = 0.00;\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_y\u001b[38;5;241m=\u001b[39mlogy, mod\u001b[38;5;241m=\u001b[39mmod )\n\u001b[1;32m    337\u001b[0m plot_grouped_curves(group_by_d_model(arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    338\u001b[0m                                      a1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m    339\u001b[0m                                      noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m                     tau_max\u001b[38;5;241m=\u001b[39mTAU_MAX, use\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    343\u001b[0m                     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer: effect of d_model; noise = 0.05\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_y\u001b[38;5;241m=\u001b[39mlogy, mod\u001b[38;5;241m=\u001b[39mmod )\n\u001b[1;32m    345\u001b[0m plot_grouped_curves(group_by_d_model(arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    346\u001b[0m                                      a1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m    347\u001b[0m                                      noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     tau_max\u001b[38;5;241m=\u001b[39mTAU_MAX, use\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m                     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer: effect of d_model; noise = 0.02\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_y\u001b[38;5;241m=\u001b[39mlogy, mod\u001b[38;5;241m=\u001b[39mmod )\n",
      "\u001b[0;31mTypeError\u001b[0m: group_by_d_model() got an unexpected keyword argument 'interaction_method'"
     ]
    }
   ],
   "source": [
    "import os, re, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def aggregate_lag_curve(lag_dict, tau_max, reduce=\"median\"):\n",
    "    \"\"\"\n",
    "    Aggregate lag_dict into lag curves.\n",
    "    Args:\n",
    "      lag_dict: {(tau, d, d'): np.ndarray[N]}\n",
    "      tau_max: maximum tau\n",
    "      reduce: 'median' | 'mean' (how to reduce across pairs)\n",
    "    Returns:\n",
    "      curve: np.ndarray[tau_max+1, N]  # per-sample lag curve\n",
    "    \"\"\"\n",
    "    # Find N from one entry\n",
    "    first_val = next(iter(lag_dict.values()))\n",
    "    N = first_val.shape[0]\n",
    "\n",
    "    curve = np.zeros((tau_max + 1, N))\n",
    "    for tau in range(tau_max + 1):\n",
    "        vals = [np.abs(v) for (tau_, d, d2), v in lag_dict.items() if tau_ == tau]  # list of [N]\n",
    "        if vals:\n",
    "            vals = np.stack(vals, axis=0)  # [num_pairs, N]\n",
    "            if reduce == \"median\":\n",
    "                curve[tau] = np.median(vals, axis=0)  # [N]\n",
    "            else:\n",
    "\n",
    "                curve[tau] = np.mean(vals, axis=0)    # [N]\n",
    "        else:\n",
    "            curve[tau] = 0.0\n",
    "    return curve  # [tau_max+1, N]\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Helpers\n",
    "# --------------------------------\n",
    "import re\n",
    "\n",
    "def parse_run_name(run_dir):\n",
    "    \"\"\"\n",
    "    Parse run folder name into a dict of hyperparams.\n",
    "    We read:\n",
    "      - leaf run dir (tau_max, num_permutations, a1, noise, explainer)\n",
    "      - parent dir for model id and hyperparams, e.g.:\n",
    "        'transformer_d_model16_layers2' -> model='transformer', d_model=16, layers=2\n",
    "        'lstm' -> model='lstm', d_model=None, layers=None\n",
    "    \"\"\"\n",
    "    name = run_dir.name\n",
    "    parent = run_dir.parent.parent.name  # e.g., 'transformer_d_model16_layers2'\n",
    "    # print(parent)\n",
    "    params = {}\n",
    "\n",
    "    # ---- parse leaf (unchanged) ----\n",
    "    patterns = {\n",
    "        \"tau_max\": r\"tau_max(\\d+)\",\n",
    "        \"num_permutations\": r\"num_permutations(\\d+)\",\n",
    "        \"a1\": r\"a1([0-9.]+)\",\n",
    "        \"noise\": r\"noise([0-9.]+)\",\n",
    "        \"explainer\": r\"explainer(\\w+)\",\n",
    "        \"interaction_method\": r\"interaction_method(\\w+)_\"\n",
    "    }\n",
    "    for key, pat in patterns.items():\n",
    "        m = re.search(pat, name)\n",
    "        if m:\n",
    "            if key in [\"tau_max\", \"num_permutations\"]:\n",
    "                params[key] = int(m.group(1))\n",
    "            elif key in [\"a1\", \"noise\"]:\n",
    "                params[key] = float(m.group(1))\n",
    "            else:\n",
    "                params[key] = m.group(1)\n",
    "\n",
    "    # ---- parse parent: model / d_model / layers (new) ----\n",
    "    # model = first token before '_' (or entire name if no '_')\n",
    "    model = parent.split(\"_\")[0]\n",
    "    params[\"model\"] = model\n",
    "\n",
    "    m_dm = re.search(r\"d_model(\\d+)\", parent)\n",
    "    m_ly = re.search(r\"layers(\\d+)\", parent)\n",
    "    params[\"d_model\"] = int(m_dm.group(1)) if m_dm else None\n",
    "    params[\"layers\"]  = int(m_ly.group(1)) if m_ly else None\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "def load_curve(run_dir, tau_max=TAU_MAX, use=\"mean\"):\n",
    "    \"\"\"Load aggregated curve from lag_dict_(mean|median).pkl or agg_T_N_interaction_curves\"\"\"\n",
    "    # fname = \"lag_dict_mean.pkl\" if use == \"mean\" else \"lag_dict_median.pkl\"\n",
    "    fname = \"agg_T_interaction_curves.pkl\" \n",
    "    \n",
    "    fpath = run_dir / fname\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Missing {fname} in {run_dir}\")\n",
    "        return None\n",
    "\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        curves = pickle.load(f)\n",
    "\n",
    "    # curve = aggregate_lag_curve(lag_dict, tau_max=tau_max)\n",
    "    # print(f\"‚úÖ Loaded {fname} from {run_dir}\")\n",
    "    return curves[:, :, FEATURE_IDX_0, FEATURE_IDX_1] # TODO: feature 0 and 0\n",
    "\n",
    "\n",
    "\n",
    "def plot_grouped_curves(group_runs, tau_max=TAU_MAX, use=\"mean\", title=None, sort_labels=True, \n",
    "                        log_y=True,\n",
    "                        mod = False):\n",
    "    \"\"\"\n",
    "    group_runs: dict[label -> list of run_dirs]\n",
    "    \"\"\"\n",
    "    # --- ensure labels are sorted numerically before iterating ---\n",
    "    if sort_labels:\n",
    "        try:\n",
    "            items = sorted(group_runs.items(), key=lambda kv: float(kv[0]))\n",
    "        except (ValueError, TypeError):\n",
    "            # fallback to string sort if labels aren't numeric\n",
    "            items = sorted(group_runs.items(), key=lambda kv: str(kv[0]))\n",
    "    else:\n",
    "        items = group_runs.items()\n",
    "        \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    for label, runs in items:\n",
    "        # print(label)\n",
    "        curves = []\n",
    "        for run_dir in runs:\n",
    "            curve = load_curve(run_dir, tau_max, use)\n",
    "            if curve is not None:\n",
    "                curves.append(curve)\n",
    "\n",
    "        if not curves:\n",
    "            continue\n",
    "        curves = np.array(curves)\n",
    "\n",
    "        # Handle 1D or 2D curves\n",
    "        if curves.ndim == 3:   # multiple [tau,N] curves stacked\n",
    "            agg = curves.mean(axis=(0,1))\n",
    "            std = curves.std(axis=(0,1))\n",
    "        elif curves.ndim == 2: # multiple [tau] curves stacked\n",
    "            agg = curves.mean(axis=0)\n",
    "            std = curves.std(axis=0)\n",
    "        else: # single curve\n",
    "            agg = curves\n",
    "            std = np.zeros_like(agg)\n",
    "\n",
    "        if mod:\n",
    "            agg = np.abs(agg)\n",
    "        plt.plot(range(len(agg)), agg, lw=2, label=str(label))\n",
    "        plt.fill_between(range(len(agg)), agg-std, agg+std, alpha=0.15)\n",
    "\n",
    "    plt.xlabel(\"Lag œÑ\")\n",
    "    plt.ylabel(\"|Interaction|\")\n",
    "    if log_y:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title(title or f\"Overlay ({use})\")\n",
    "\n",
    "    # --- sort legend labels ---\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    # if sort_labels:\n",
    "    #     try:\n",
    "    #         labels_numeric = [float(l) for l in labels]\n",
    "    #         order = np.argsort(labels_numeric)\n",
    "    #     except ValueError:\n",
    "    #         order = np.argsort(labels)\n",
    "    #     handles = [handles[i] for i in order]\n",
    "    #     labels = [labels[i] for i in order]\n",
    "    plt.legend(handles, labels, fontsize=8)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Collect all runs\n",
    "# --------------------------------\n",
    "# all_runs = [p for p in BASE_DIR.rglob(\"*\") if p.is_dir() and (p/\"lag_dict_mean.pkl\").exists()]\n",
    "all_runs = [p for p in BASE_DIR.rglob(\"*\") if p.is_dir() and (p/\"agg_T_interaction_curves.pkl\").exists()]\n",
    "\n",
    "meta = [(r, parse_run_name(r)) for r in all_runs]\n",
    "\n",
    "# --- quick summary of discovered hyperparams before plotting ---\n",
    "from collections import defaultdict\n",
    "summary = defaultdict(set)\n",
    "for _, p in meta:\n",
    "    for k, v in p.items():\n",
    "        summary[k].add(v)\n",
    "print(\"üîé Discovered hyperparams in run dirs:\")\n",
    "for k in sorted(summary.keys()):\n",
    "    vals = sorted(x for x in summary[k] if x is not None)\n",
    "    print(f\"  {k}: {vals}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Example overlays\n",
    "# --------------------------------\n",
    "\n",
    "# Compare different a1 (fix noise & arch)\n",
    "def group_by_a1(arch=\"lstm\", noise=0.1):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        if params.get(\"noise\")==noise and arch in str(r):\n",
    "            group[params[\"a1\"]] = group.get(params[\"a1\"], []) + [r]\n",
    "    return group\n",
    "\n",
    "\n",
    "# Compare different noise levels (fix a1 & arch)\n",
    "def group_by_noise(arch=\"lstm\", a1=0.2):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        if params.get(\"a1\")==a1 and arch in str(r):\n",
    "            group[params[\"noise\"]] = group.get(params[\"noise\"], []) + [r]\n",
    "    return group\n",
    "\n",
    "\n",
    "# Compare different num_permutations (fix coeff_scale, noise & arch)\n",
    "def group_by_permutations(arch=\"lstm\", a1=0.2, noise=0.1):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        if params.get(\"a1\")==a1 and params.get(\"noise\")==noise and arch in str(r):\n",
    "            group[params[\"num_permutations\"]] = group.get(params[\"num_permutations\"], []) + [r]\n",
    "    return group\n",
    "\n",
    "\n",
    "# Compare architectures (fix a1, noise, permutations)\n",
    "def group_by_arch(a1=0.2, noise=0.1, num_permutations=20):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        # print(r, params)\n",
    "        if (params.get(\"a1\")==a1 and \n",
    "            params.get(\"noise\")==noise and \n",
    "            params.get(\"num_permutations\")==num_permutations):\n",
    "            arch = r.parts[3]  # \"lstm\", \"tcn\", etc.\n",
    "            # print(arch)\n",
    "            group[arch] = group.get(arch, []) + [r]\n",
    "    return group\n",
    "\n",
    "# Compare different d_model (fix arch, a1, noise, layers)\n",
    "def group_by_d_model(arch=\"transformer\", a1=0.2, noise=0.1, \n",
    "                     layers=2,\n",
    "                     interaction_methord = \"ih\"):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        if (params.get(\"model\")==arch and\n",
    "            # params.get(\"a1\")==a1 and\n",
    "            params.get(\"noise\")==noise and\n",
    "            params.get(\"layers\")==layers and\n",
    "            params.get(\"d_model\") is not None):\n",
    "            dm = params[\"d_model\"]\n",
    "            group[dm] = group.get(dm, []) + [r]\n",
    "    return group\n",
    "\n",
    "# Compare different layers (fix model, a1, noise, d_model)\n",
    "def group_by_layers(arch=\"transformer\", a1=0.2, noise=0.1, d_model=32):\n",
    "    group = {}\n",
    "    for r, params in meta:\n",
    "        if (params.get(\"model\")==arch and\n",
    "            params.get(\"a1\")==a1 and\n",
    "            params.get(\"noise\")==noise and\n",
    "            params.get(\"d_model\")==d_model and\n",
    "            params.get(\"layers\") is not None):\n",
    "            ly = params[\"layers\"]\n",
    "            group[ly] = group.get(ly, []) + [r]\n",
    "    return group\n",
    "\n",
    "\n",
    "logy=True\n",
    "mod = True\n",
    "# plot_grouped_curves(group_by_a1(\"transformer\", noise=0.05),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Transformer: Effect of a1; noise = 0.05\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"transformer\", noise=0.1),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Transformer: Effect of a1; noise = 0.1\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"transformer\", noise=0.2),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Transformer: Effect of a1; noise = 0.2\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"transformer\", noise=0.4),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Transformer: Effect of a1; noise = 0.4\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"lstm\", noise=0.05),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"LSTM: Effect of a1; noise = 0.05\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"lstm\", noise=0.1),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"LSTM: Effect of a1; noise = 0.1\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"lstm\", noise=0.2),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"LSTM: Effect of a1; noise = 0.2\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_a1(\"lstm\", noise=0.4),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"LSTM: Effect of a1; noise = 0.4\", log_y=logy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_grouped_curves(group_by_noise(\"lstm\", a1=0.05),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of noise; a1 = 0.05\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_noise(\"lstm\", a1=0.1),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of noise; a1 = 0.1\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_noise(\"lstm\", a1=0.2),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of noise; a1 = 0.2\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_noise(\"lstm\", a1=0.4),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of noise; a1 = 0.4\", log_y=logy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_grouped_curves(group_by_permutations(\"lstm\", a1=0.2, noise=0.1),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of num_permutations\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_arch(a1=0.2, noise=0.1, num_permutations=20),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\", title=\"Effect of architecture\", log_y=logy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# same axes; vary d_model (keep layers fixed)\n",
    "plot_grouped_curves(group_by_d_model(arch=\"transformer\", \n",
    "                                     a1=0.2, \n",
    "                                     noise=0.00, \n",
    "                                     layers=2,\n",
    "                                     interaction_method = interaction_method),\n",
    "                    tau_max=TAU_MAX, use=\"mean\",\n",
    "                    title=\"Transformer: effect of d_model; noise = 0.00;\", log_y=logy, mod=mod )\n",
    "\n",
    "plot_grouped_curves(group_by_d_model(arch=\"transformer\", \n",
    "                                     a1=0.2, \n",
    "                                     noise=0.05, \n",
    "                                     layers=2,\n",
    "                                     interaction_method = interaction_method), \n",
    "                    tau_max=TAU_MAX, use=\"mean\",\n",
    "                    title=\"Transformer: effect of d_model; noise = 0.05\", log_y=logy, mod=mod )\n",
    "\n",
    "plot_grouped_curves(group_by_d_model(arch=\"transformer\", \n",
    "                                     a1=0.2, \n",
    "                                     noise=0.02, \n",
    "                                     layers=2,\n",
    "                                     interaction_method = interaction_method), \n",
    "\n",
    "                    tau_max=TAU_MAX, use=\"mean\",\n",
    "                    title=\"Transformer: effect of d_model; noise = 0.02\", log_y=logy, mod=mod )\n",
    "\n",
    "plot_grouped_curves(group_by_d_model(arch=\"transformer\", \n",
    "                                     a1=0.2, \n",
    "                                     noise=0.1, \n",
    "                                     layers=2,\n",
    "                                     interaction_method = interaction_method), \n",
    "                    tau_max=TAU_MAX, use=\"mean\",\n",
    "                    title=\"Transformer: effect of d_model; noise = 0.1\", log_y=logy ,mod=mod )\n",
    "\n",
    "\n",
    "\n",
    "# plot_grouped_curves(group_by_d_model(arch=\"transformer\", a1=0.2, noise=0.1, layers=2),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\",\n",
    "#                     title=\"Transformer: effect of d_model (layers=2)\", log_y=logy)\n",
    "\n",
    "# plot_grouped_curves(group_by_d_model(arch=\"transformer\", a1=0.2, noise=0.1, layers=2),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\",\n",
    "#                     title=\"Transformer: effect of d_model (layers=2)\", log_y=logy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# same axes; vary layers (keep d_model fixed)\n",
    "# plot_grouped_curves(group_by_layers(arch=\"transformer\", a1=0.2, noise=0.1, d_model=32),\n",
    "#                     tau_max=TAU_MAX, use=\"mean\",\n",
    "#                     title=\"Transformer: effect of layers (d_model=32)\", log_y=logy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728761b",
   "metadata": {},
   "source": [
    "### Loc@K and Loc50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da650825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n",
      "‚ö†Ô∏è No data to plot\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Load metrics from metrics1.json\n",
    "# -----------------------------\n",
    "def load_metrics(run_dir):\n",
    "    fpath = run_dir / \"metrics1.json\"\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Missing metrics1.json in {run_dir}\")\n",
    "        return None\n",
    "    with open(fpath, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    return {\n",
    "        \"loc_at_k\": metrics.get(\"loc_at_k\", None),  # or whatever K you used\n",
    "        \"loc50\": metrics.get(\"loc50\", None)\n",
    "    }\n",
    "def plot_metric_group(group_runs, metric=\"loc_at_k\", title=None, sort_labels=True):\n",
    "    \"\"\"\n",
    "    group_runs: dict[label -> list of run_dirs]\n",
    "    metric: \"loc_at_k\" or \"loc50\"\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for label, runs in group_runs.items():\n",
    "        vals = []\n",
    "        for run_dir in runs:\n",
    "            m = load_metrics(run_dir)\n",
    "            if m and m[metric] is not None:\n",
    "                vals.append(m[metric])\n",
    "        if vals:\n",
    "            data[label] = vals\n",
    "\n",
    "    if not data:\n",
    "        print(\"‚ö†Ô∏è No data to plot\")\n",
    "        return\n",
    "\n",
    "    labels, means, stds = [], [], []\n",
    "    for label, vals in data.items():\n",
    "        labels.append(label)\n",
    "        means.append(np.mean(vals))\n",
    "        stds.append(np.std(vals))\n",
    "\n",
    "    # sort labels if possible\n",
    "    if sort_labels:\n",
    "        try:\n",
    "            labels_numeric = [float(l) for l in labels]\n",
    "            order = np.argsort(labels_numeric)\n",
    "        except ValueError:\n",
    "            order = np.argsort(labels)\n",
    "        labels = [labels[i] for i in order]\n",
    "        means = [means[i] for i in order]\n",
    "        stds = [stds[i] for i in order]\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    x = range(len(labels))\n",
    "    plt.plot(x, means, marker=\"o\", lw=2, label=metric)\n",
    "    # plt.fill_between(x, np.array(means)-np.array(stds), np.array(means)+np.array(stds), alpha=0.2)\n",
    "    plt.xticks(x, labels)\n",
    "    plt.xlabel(\"Hyperparam values\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title or metric)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example comparisons\n",
    "# -----------------------------\n",
    "plot_metric_group(group_by_a1(\"lstm\", noise=0.1),\n",
    "                  metric=\"loc_at_k\", title=\"Loc@K vs a1\")\n",
    "\n",
    "plot_metric_group(group_by_a1(\"lstm\", noise=0.1),\n",
    "                  metric=\"loc50\", title=\"Loc@50 vs a1\")\n",
    "\n",
    "plot_metric_group(group_by_noise(\"lstm\", a1=0.2),\n",
    "                  metric=\"loc_at_k\", title=\"Loc@K vs noise\")\n",
    "\n",
    "plot_metric_group(group_by_noise(\"lstm\", a1=0.2),\n",
    "                  metric=\"loc50\", title=\"Loc@50 vs noise\")\n",
    "\n",
    "plot_metric_group(group_by_permutations(\"lstm\", a1=0.2, noise=0.1),\n",
    "                  metric=\"loc_at_k\", title=\"Loc@K vs num_permutations\")\n",
    "\n",
    "plot_metric_group(group_by_permutations(\"lstm\", a1=0.2, noise=0.1),\n",
    "                  metric=\"loc50\", title=\"Loc@50 vs num_permutations\")\n",
    "\n",
    "plot_metric_group(group_by_arch(a1=0.2, noise=0.1, num_permutations=5),\n",
    "                  metric=\"loc_at_k\", title=\"Loc@K vs architecture\")\n",
    "\n",
    "plot_metric_group(group_by_arch(a1=0.2, noise=0.1, num_permutations=5),\n",
    "                  metric=\"loc50\", title=\"Loc@50 vs architecture\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a6195",
   "metadata": {},
   "source": [
    "### Table loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfb56b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== d_model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_model</th>\n",
       "      <th>loc_at_k</th>\n",
       "      <th>loc50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.709242</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.504234</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.480586</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_model  loc_at_k  loc50\n",
       "0       16  0.709242   20.0\n",
       "2       32  0.504234    5.0\n",
       "1       64  0.480586    6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No metrics found for noise\n",
      "‚ö†Ô∏è No metrics found for num_permutations\n",
      "‚ö†Ô∏è No metrics found for architecture\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def collect_metrics(group_runs, group_name):\n",
    "    \"\"\"\n",
    "    group_runs: dict[label -> list of run_dirs]\n",
    "    Returns a DataFrame with columns [label, loc_at_k, loc50]\n",
    "\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label, runs in group_runs.items():\n",
    "        vals_k, vals_50 = [], []\n",
    "        for run_dir in runs:\n",
    "            m = load_metrics(run_dir)\n",
    "            if m:\n",
    "                if m.get(\"loc_at_k\") is not None:\n",
    "                    vals_k.append(m[\"loc_at_k\"])\n",
    "                if m.get(\"loc50\") is not None:\n",
    "                    vals_50.append(m[\"loc50\"])\n",
    "        if vals_k or vals_50:\n",
    "            rows.append({\n",
    "                group_name: label,\n",
    "                \"loc_at_k\": np.mean(vals_k) if vals_k else None,\n",
    "                # \"loc_at_k_std\": np.std(vals_k) if vals_k else None,\n",
    "                \"loc50\": np.mean(vals_50) if vals_50 else None,\n",
    "                # \"loc50_std\": np.std(vals_50) if vals_50 else None\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def print_group_table(group_runs, group_name):\n",
    "    df = collect_metrics(group_runs, group_name)\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No metrics found for {group_name}\")\n",
    "        return\n",
    "    print(f\"\\n=== {group_name} ===\")\n",
    "    display(df.sort_values(group_name))\n",
    "\n",
    "arch = \"transformer\"\n",
    "\n",
    "# Group by coeff_scale\n",
    "# print_group_table(group_by_a1(arch, noise=0.1), \"a1\")\n",
    "\n",
    "\n",
    "# Group by d_model\n",
    "print_group_table(group_by_d_model(arch), \"d_model\")\n",
    "\n",
    "print_group_table(group_by_noise(arch, a1=0.2), \"noise\")\n",
    "# Group by num_permutations\n",
    "print_group_table(group_by_permutations(arch, a1=0.2, noise=0.1), \"num_permutations\")\n",
    "\n",
    "# Group by architecture\n",
    "print_group_table(group_by_arch(a1=0.2, noise=0.1, num_permutations=20), \"architecture\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
